{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krishnaugale353/Pnemonia-Detection-using-ML/blob/main/Pnemonia_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LunHPDK5AXeL"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow-gpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YO8K5KpukzMH"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Flatten,Dense\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import matplotlib.pyplot as plot\n",
        "from glob import glob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AhL19gbfY1a8"
      },
      "outputs": [],
      "source": [
        "IMAGESHAPE = [224, 224, 3]\n",
        "training_data = '/content/drive/MyDrive/chest_xray/chest_xray/train'\n",
        "testing_data = \"/content/drive/MyDrive/chest_xray/chest_xray/test\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0rxJShbYkVh",
        "outputId": "d517103b-188d-40c7-cabf-c885466db641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb 11 11:25:47 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "23T-WnUcY239"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FK0ec49hjB0Y"
      },
      "outputs": [],
      "source": [
        "vgg_model = VGG16(input_shape=IMAGESHAPE, weights='imagenet', include_top=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LZn3LsthjMEz"
      },
      "outputs": [],
      "source": [
        "for each_layer in vgg_model.layers:\n",
        "\teach_layer.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2FQIKMkJjN9c"
      },
      "outputs": [],
      "source": [
        "classes = glob('/content/drive/MyDrive/chest_xray/chest_xray/test/*')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5YAgLMvWjgIy"
      },
      "outputs": [],
      "source": [
        "flatten_layer = Flatten()(vgg_model.output)\n",
        "prediction = Dense(len(classes), activation='softmax')(flatten_layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z78HXDujmQT",
        "outputId": "7dac162d-498a-4a5b-f464-fa26c858a932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 50178     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14764866 (56.32 MB)\n",
            "Trainable params: 50178 (196.01 KB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "final_model = Model(inputs=vgg_model.input, outputs=prediction)\n",
        "final_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sPUte9m5jpkN"
      },
      "outputs": [],
      "source": [
        "final_model.compile(\n",
        "loss='categorical_crossentropy',\n",
        "optimizer='adam',\n",
        "metrics=['accuracy']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "acSSeTFojuGH"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "\t\t\t\t\t\t\t\tshear_range = 0.2,\n",
        "\t\t\t\t\t\t\t\tzoom_range = 0.2,\n",
        "\t\t\t\t\t\t\t\thorizontal_flip = True)\n",
        "testing_datagen = ImageDataGenerator(rescale =1. / 255)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKkYt-Kdjzzk",
        "outputId": "108a3094-77d1-4c6e-9903-70e75bc9383b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/chest_xray/chest_xray/train',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\ttarget_size = (224, 224),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tbatch_size = 6,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tclass_mode = 'categorical')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC-cdDytkTon",
        "outputId": "910fe31f-9c35-4444-c2f8-68abfe0317b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 640 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_set = testing_datagen.flow_from_directory('/content/drive/MyDrive/chest_xray/chest_xray/test',\n",
        "\t\t\t\t\t\t\t\t\t\t\ttarget_size = (224, 224),\n",
        "\t\t\t\t\t\t\t\t\t\t\tbatch_size = 6,\n",
        "\t\t\t\t\t\t\t\t\t\t\tclass_mode = 'categorical')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PSrF17PYfnY",
        "outputId": "07bf0ed7-236d-43c0-f655-1779c2ead771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the training dataset: 870\n",
            "Size of the testing dataset: 107\n"
          ]
        }
      ],
      "source": [
        "print(\"Size of the training dataset:\", len(training_set))\n",
        "print(\"Size of the testing dataset:\", len(test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nlTHEL5DZfGh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXLEkFookpeK",
        "outputId": "b57db91d-120b-4331-fd5b-c95895ba682c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-0133b02f9370>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  fitted_model = final_model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "870/870 [==============================] - 670s 765ms/step - loss: 0.2563 - accuracy: 0.9235 - val_loss: 2.1167 - val_accuracy: 0.6750\n",
            "Epoch 2/5\n",
            "870/870 [==============================] - 139s 160ms/step - loss: 0.2290 - accuracy: 0.9442 - val_loss: 0.8794 - val_accuracy: 0.8734\n",
            "Epoch 3/5\n",
            "870/870 [==============================] - 140s 161ms/step - loss: 0.1506 - accuracy: 0.9597 - val_loss: 0.4288 - val_accuracy: 0.9141\n",
            "Epoch 4/5\n",
            "870/870 [==============================] - 137s 157ms/step - loss: 0.1668 - accuracy: 0.9605 - val_loss: 1.0779 - val_accuracy: 0.8438\n",
            "Epoch 5/5\n",
            "870/870 [==============================] - 138s 158ms/step - loss: 0.1853 - accuracy: 0.9571 - val_loss: 1.1490 - val_accuracy: 0.8531\n"
          ]
        }
      ],
      "source": [
        "fitted_model = final_model.fit_generator(\n",
        "training_set,\n",
        "validation_data=test_set,\n",
        "epochs=5,\n",
        "steps_per_epoch=len(training_set),\n",
        "validation_steps=len(test_set)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aHDZJnvlxHC",
        "outputId": "3600c787-57e6-4c2a-c306-5b1f3d5bf72f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "final_model.save('our_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw39m7LImXjt",
        "outputId": "065e7cba-2d1f-4223-ca8c-0a6966a98579"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Keras-Preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.23.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.16.0)\n",
            "Installing collected packages: Keras-Preprocessing\n",
            "Successfully installed Keras-Preprocessing-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install Keras-Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9yIaJbYl0_X",
        "outputId": "0d41c31f-2d50-486b-fb8e-5be17b01ec9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Person is affected with Pneumonia.\n",
            "Predictions: [[0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "from keras_preprocessing import image\n",
        "from keras.models import load_model\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "model=load_model('our_model.h5') #Loading our model\n",
        "img=image.load_img('/content/drive/MyDrive/chest_xray/chest_xray/test/PNEUMONIA/person100_bacteria_475.jpeg',target_size=(224,224))\n",
        "imagee=image.img_to_array(img) #Converting the X-Ray into pixels\n",
        "imagee=np.expand_dims(imagee, axis=0)\n",
        "img_data=preprocess_input(imagee)\n",
        "prediction=model.predict(img_data)\n",
        "if prediction[0][0]>prediction[0][1]: #Printing the prediction of model.\n",
        "\tprint('Person is safe.')\n",
        "else:\n",
        "\tprint('Person is affected with Pneumonia.')\n",
        "print(f'Predictions: {prediction}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_s72H9zZglg",
        "outputId": "bebd46ad-39a9-4bb8-c814-22ebac504d5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107/107 [==============================] - 8s 73ms/step - loss: 1.1490 - accuracy: 0.8531\n",
            "Testing Accuracy: 85.31%\n",
            "107/107 [==============================] - 14s 133ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 53 189]\n",
            " [103 295]]\n",
            "\n",
            "Classification Report:\n",
            "                                                             precision    recall  f1-score   support\n",
            "\n",
            "   /content/drive/MyDrive/chest_xray/chest_xray/test/NORMAL       0.34      0.22      0.27       242\n",
            "/content/drive/MyDrive/chest_xray/chest_xray/test/PNEUMONIA       0.61      0.74      0.67       398\n",
            "\n",
            "                                                   accuracy                           0.54       640\n",
            "                                                  macro avg       0.47      0.48      0.47       640\n",
            "                                               weighted avg       0.51      0.54      0.52       640\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "# Evaluate the model on the testing set\n",
        "evaluation = final_model.evaluate(test_set, steps=len(test_set))\n",
        "\n",
        "# Print overall accuracy\n",
        "print(\"Testing Accuracy: {:.2f}%\".format(evaluation[1] * 100))\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = final_model.predict(test_set, steps=len(test_set))\n",
        "\n",
        "# Convert predictions to binary values (0 or 1)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true labels\n",
        "true_classes = test_set.classes\n",
        "\n",
        "# Print confusion matrix and classification report\n",
        "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "classification_rep = classification_report(true_classes, predicted_classes, target_names=classes)\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n99E1Zzlbt6w",
        "outputId": "e6492ce3-4e4f-4e77-ec24-b1c30dbec504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 640 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data generators for training and testing\n",
        "train_datagen = ImageDataGenerator()\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "# Load the training dataset\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/chest_xray/chest_xray/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=6,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load the test dataset\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/chest_xray/chest_xray/test',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=6,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Initialize and train the SVM model\n",
        "svm_model = make_pipeline(StandardScaler(), SVC(kernel='linear', C=2))\n",
        "\n",
        "# Extract images and labels from the entire training set\n",
        "train_images = []\n",
        "train_labels = []\n",
        "\n",
        "for images_batch, labels_batch in training_set:\n",
        "    train_images.append(images_batch)\n",
        "    train_labels.append(labels_batch)\n",
        "    if len(train_images) * training_set.batch_size >= len(training_set.filenames):\n",
        "        break\n",
        "\n",
        "# Concatenate the batches into a single array\n",
        "train_images = np.concatenate(train_images)\n",
        "train_labels = np.concatenate(train_labels)\n",
        "\n",
        "# Reshape the data\n",
        "train_images_flattened = train_images.reshape(train_images.shape[0], -1)\n",
        "\n",
        "# Train the SVM model on the entire training dataset\n",
        "svm_model.fit(train_images_flattened, np.argmax(train_labels, axis=1))\n",
        "\n",
        "# Load and accumulate predictions over all batches of the test dataset\n",
        "all_predictions_svm = []\n",
        "all_true_labels = []\n",
        "\n",
        "for images_batch, labels_batch in test_set:\n",
        "    # Reshape the batch data\n",
        "    images_batch_flattened = images_batch.reshape(images_batch.shape[0], -1)\n",
        "\n",
        "    # Predict labels using the SVM model\n",
        "    predictions_batch = svm_model.predict(images_batch_flattened)\n",
        "\n",
        "    # Append predictions and true labels\n",
        "    all_predictions_svm.extend(predictions_batch)\n",
        "    all_true_labels.extend(np.argmax(labels_batch, axis=1))\n",
        "\n",
        "# Convert to numpy arrays for easier manipulation\n",
        "all_predictions_svm = np.array(all_predictions_svm)\n",
        "all_true_labels = np.array(all_true_labels)\n",
        "\n",
        "# Print confusion matrix and classification report for SVM\n",
        "conf_matrix_svm = confusion_matrix(all_true_labels, all_predictions_svm)\n",
        "classification_rep_svm = classification_report(all_true_labels, all_predictions_svm)\n",
        "\n",
        "print(\"\\nSVM - Confusion Matrix:\")\n",
        "print(conf_matrix_svm)\n",
        "\n",
        "print(\"\\nSVM - Classification Report:\")\n",
        "print(classification_rep_svm)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NOJ_wPybE7Cw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ySwn1CnkP9VRP9pQwssf5lUPPLcfWgMq",
      "authorship_tag": "ABX9TyPX4itAd/ieQQmuyX6cIfpj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}